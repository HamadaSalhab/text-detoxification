{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Users/hamadasalhab/Library/CloudStorage/OneDrive-АНОВОУниверситетИннополис/Disk D/Innopolis Study Materials/F23/PMLDL/Assignments/Assignment#01/text-detoxification/src/data/../../data/raw/filtered_paranmt.zip\n",
      "All set. The dataset can be found in project_root_dir/data/raw.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "from src.data.make_dataset import get_dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "DATASET_PATH = '../data/raw/filtered_paranmt/filtered.tsv'\n",
    "\n",
    "# Load data\n",
    "\n",
    "df = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "MAX_LENGTH = 512  # BERT's maximum sequence length\n",
    "\n",
    "def preprocess_text_for_bert(text, max_length=MAX_LENGTH):\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        text, \n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        # return_tensors='pt'  # Returning tensors\n",
    "    )\n",
    "    return encoded[\"input_ids\"], encoded[\"attention_mask\"]\n",
    "\n",
    "# Applying preprocessing to the reference and translation columns\n",
    "df['reference_input_ids'], df['reference_attention_mask'] = zip(*df['reference'].apply(preprocess_text_for_bert))\n",
    "\n",
    "df['translation_input_ids'], df['translation_attention_mask'] = zip(*df['translation'].apply(preprocess_text_for_bert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "      <th>reference_input_ids</th>\n",
       "      <th>reference_attention_mask</th>\n",
       "      <th>translation_input_ids</th>\n",
       "      <th>translation_attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>0.981983</td>\n",
       "      <td>[101, 2065, 2632, 6673, 2003, 9451, 2014, 2007...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 2065, 2632, 6673, 14295, 2014, 2007, 201...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.065473</td>\n",
       "      <td>0.999039</td>\n",
       "      <td>[101, 2085, 2017, 1005, 2128, 2893, 11808, 101...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[101, 2017, 1005, 2128, 3352, 19424, 1012, 102...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.985068</td>\n",
       "      <td>[101, 2092, 1010, 2057, 2071, 8622, 2115, 2166...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>[101, 2092, 1010, 2057, 2064, 8622, 2115, 2166...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.053362</td>\n",
       "      <td>0.994215</td>\n",
       "      <td>[101, 6289, 999, 10608, 1010, 2017, 1005, 2310...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 10608, 1010, 2017, 2031, 2000, 5256, 203...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.999348</td>\n",
       "      <td>[101, 1045, 1005, 2310, 2288, 4449, 2000, 2404...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[101, 1045, 2031, 4449, 2000, 3102, 2014, 1012...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          reference  \\\n",
       "0           0  If Alkar is flooding her with psychic waste, t...   \n",
       "1           1                          Now you're getting nasty.   \n",
       "2           2           Well, we could spare your life, for one.   \n",
       "3           3          Ah! Monkey, you've got to snap out of it.   \n",
       "4           4                   I've got orders to put her down.   \n",
       "\n",
       "                                         translation  similarity  lenght_diff  \\\n",
       "0  if Alkar floods her with her mental waste, it ...    0.785171     0.010309   \n",
       "1                        you're becoming disgusting.    0.749687     0.071429   \n",
       "2                      well, we can spare your life.    0.919051     0.268293   \n",
       "3                       monkey, you have to wake up.    0.664333     0.309524   \n",
       "4                         I have orders to kill her.    0.726639     0.181818   \n",
       "\n",
       "    ref_tox   trn_tox                                reference_input_ids  \\\n",
       "0  0.014195  0.981983  [101, 2065, 2632, 6673, 2003, 9451, 2014, 2007...   \n",
       "1  0.065473  0.999039  [101, 2085, 2017, 1005, 2128, 2893, 11808, 101...   \n",
       "2  0.213313  0.985068  [101, 2092, 1010, 2057, 2071, 8622, 2115, 2166...   \n",
       "3  0.053362  0.994215  [101, 6289, 999, 10608, 1010, 2017, 1005, 2310...   \n",
       "4  0.009402  0.999348  [101, 1045, 1005, 2310, 2288, 4449, 2000, 2404...   \n",
       "\n",
       "                            reference_attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...   \n",
       "\n",
       "                               translation_input_ids  \\\n",
       "0  [101, 2065, 2632, 6673, 14295, 2014, 2007, 201...   \n",
       "1  [101, 2017, 1005, 2128, 3352, 19424, 1012, 102...   \n",
       "2  [101, 2092, 1010, 2057, 2064, 8622, 2115, 2166...   \n",
       "3  [101, 10608, 1010, 2017, 2031, 2000, 5256, 203...   \n",
       "4  [101, 1045, 2031, 4449, 2000, 3102, 2014, 1012...   \n",
       "\n",
       "                          translation_attention_mask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERIM_DATASET_PATH = '../data/interim/preprocessed_bert2bert.tsv'\n",
    "\n",
    "df.to_csv(INTERIM_DATASET_PATH, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
